- 이 페이지는 [김성동](https://github.com/DSKSD)님이 작성해주셨습니다! 감사합니다

## 필요한 사전 지식
- 확률론
- 선형대수
- 최적화

## 개념
- Word Representation : 텍스트를 처리하기 위한 가장 기본 단위인 '단어'를 표상하는 방법론
	- Bag-of-Word
	- TF-IDF
	- Word2Vec
	- GloVe
	- FastText
- Text Classification : 텍스트를 사전정의 된 카테고리 중 하나로 분류하는 테스크
	- Sentiment Analysis
	- Document Classification
	- Intent Classification
	- ...
- Semantic/Syntatic Parsing : 텍스트의 구조와 의미를 분석하여 정보를 추출하는 테스크
	- Named Entity Recognization
	- Semantic Role Labeling
	- Relation/Information Extraction
	- POS Tagging
	- Constituency Parsing 
	- Dependency Parsing
	- ...
- Disambiguation : 의미적 모호함을 해소하는 테스크
	- Word-Sense Deambigution
	- Coreference Resolution
- Language model : $$y(w_t|w_{t-1},...,w_1)$$ 이전 단어들이 주었을 때 timestep t 시점의 단어를 예측하는 테스크
	- Machine Translation도 Conditional Language model로 볼 수 있음 $$y(w_t|w_{t-1},...,w_1,S)$$ 
	- S는 Source language sequence
- Sequence Transduction : Source Sequence가 주어졌을 때 Target Sequence로 변환하는 테스크
	- Machine Translation
	- Dialogue System (Response Generation)
	- Summarization
	- Paraphrasing
	- ...

## 최근 이론
- Advanced Attetion mechanism 
- Latent Random Variable Models
- Reinforcement Learning
- Transfer Learning / Multi-task Learning
- Contextualized Word Representation (ELMo, CoVe)

## 추천 공부 방법
- 텍스트는 기본적으로 단어/음절/자소의 시퀀스를 다뤄야 하는 분야이므로 파이썬 리스트 자료구조를 자유자재로 쥐락펴락할 수 있어야 합니다
- 리스트의 원소들에 대한 indexing, selecting, mapping 등이 익숙해질 때까지 반복 숙달!
- 머신러닝의 기초적인 부분이 부족하다면 '코세라 머신러닝 코스'를 먼저 수강하시길 추천합니다
- Supervised Learning에 대한 이해가 충분하다면 Bag-of-Word 방법과 Logistic Regression 모델을 사용하여 간단한 Text Classifier부터 만들어보길 바랍니다
- (텍스트/카테고리) 페어로 이뤄진 데이터를 자유자재로 전처리하고 위의 모델을 만들 수 있을 때쯤 Word Representation에 대해 공부하고 고찰해보세요
- 그 다음으로 BoW(Bag-of-Word) 방식이 아닌 Word Vector(Distributed Word Representation)을 이용하여 딥러닝 기반의 Text Classifier를 모델링해보기
- 여기까지 자유자재로 가능하다면 이 후로는 개인의 관심사에 따라 재밌는 테스크를 연구하고 구현해보기(개인적으로는 Sequence Tagging 모델에 도전해보길 바랍니다)
- 모델이 생각처럼 동작하지 않을 때 해결책을 찾고 적용해보기 (문제를 해결하기 위한 방법론에 대한 탐구)

## 참고하면 좋은 강의/자료
- [딥 러닝을 이용한 자연어 처리 입문](https://wikidocs.net/book/2155)
- [김기현의 자연어 처리 딥러닝 캠프 파이토치 편](http://www.yes24.com/Product/Goods/74802622) : 자연어 기반 자료 중 정말 Top이라고 생각하는 책입니다 :)
- [NLP Tutorial](https://github.com/graykode/nlp-tutorial)
- 박규봉님의 [딥러닝 커리어 FAQ](https://github.com/Kyubyong/dl_career_faq)
- 김기현님의 [Natural Language Processing with PyTorch](https://kh-kim.gitbook.io/natural-language-processing-with-pytorch/)
- 김현중님의 [Textmining Tutorial](https://github.com/lovit/textmining-tutorial)
- [deeplearningbook](https://www.deeplearningbook.org/)
- [Stanford CS224n](http://web.stanford.edu/class/cs224n/syllabus.html)
- [oxford deelnlp](https://github.com/oxford-cs-deepnlp-2017/lectures)
- [NLP progress](https://github.com/sebastianruder/NLP-progress)
- [CMU Neural Networks for NLP](http://phontron.com/class/nn4nlp2017/schedule.html)
- [Georgia Tech Natural Language](https://github.com/jacobeisenstein/gt-nlp-class)
- [주재걸 교수님의 Natural Language Processing Applications](https://www.youtube.com/watch?v=S0mOsBlJ2TE&list=PLep-kTP3NkcPqughb3SOLiSqza_koBewh)
- [조경현 교수님의 딥러닝을 이용한 자연어 처리](https://www.edwith.org/deepnlp)